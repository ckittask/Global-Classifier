# Ollama Client and Model Settings
model_name: "gemma3:1b-it-qat"
ollama_host: "http://ollama:11434"
ollama_timeout: 60
ollama_max_retries: 3
ollama_retry_delay: 5

# Generation defaults
generation_defaults:
  temperature: 0.95
  max_tokens_per_response: 5000
  num_predict: 5000

# Content Processing
content_processing:
  max_content_length: 15000
  content_overlap: 500

# Language and Prompt Settings
language_settings:
  default_system_prompt: "You are a helpful assistant providing accurate information based on topic content."
  default_language: "et"
  supported_languages:
    en: "English"
    et: "Estonian"
    fi: "Finnish"

# Storage configuration
storage:
  datasets_dir: "datasets"
  templates_dir: "templates"
  user_configs_dir: "user_configs"
  
# Default Output Settings
output_defaults:
  save_format: "json"
  supported_formats:
    - "json"
    - "text"